# -*- coding: utf-8 -*-
"""demo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F-vRTaO6bmHx0kzrdST3cVj-QqvoR_-b
"""

from autogluon.tabular import TabularPredictor
from sklearn.decomposition import PCA, TruncatedSVD
import scipy.sparse as sp
import pickle
from sklearn.model_selection import train_test_split
import csv
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, log_loss
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

# Read sequences
sequences = list()
with open('sequences.txt', 'r') as f:
    for line in f:
        sequences.append(line[:-1])

# Split data into training and test sets
sequences_train = list()
sequences_test = list()
proteins_test = list()
y_train = list()
with open('graph_labels.txt', 'r') as f:
    for i, line in enumerate(f):
        t = line.split(',')
        if len(t[1][:-1]) == 0:
            proteins_test.append(t[0])
            sequences_test.append(sequences[i])
        else:
            sequences_train.append(sequences[i])
            y_train.append(int(t[1][:-1]))


"""### embedding"""

with open('./embedding/train_global_embedding', 'rb') as f:
    X_train_sequencial_embedding = pickle.load(f)
with open('./embedding/test_global_embedding', 'rb') as f:
    X_test_sequencial_embedding = pickle.load(f)

X_train_structrual_embedding= np.load('./embedding/train_structrual_embedding.npy')
X_test_structrual_embedding= np.load('./embedding/test_structrual_embedding.npy')

X_train = np.concatenate((X_train_sequencial_embedding, X_train_structrual_embedding), axis=1)
X_test = np.concatenate((X_test_sequencial_embedding, X_test_structrual_embedding), axis=1)
"""### dimension reduction"""
print(X_train.shape, X_test.shape)

# X = np.vstack((X_train.toarray(), X_test.toarray()))
X = np.vstack((X_train, X_test))
X.shape

X_sparse = sp.csr_matrix(X)
svd = TruncatedSVD(n_components=300)
svd.fit(X)

X_new = svd.transform(X)

X_train_new, X_test_new = np.split(X_new, [X_train.shape[0]])

X_train_new.shape, X_test_new.shape

df_train = pd.DataFrame(X_train_new)
df_test = pd.DataFrame(X_test_new)
df_train.columns = range(df_train.shape[1])
df_train['class'] = y_train
"""### automl"""

predictor = TabularPredictor(
    label='class', eval_metric='log_loss').fit(df_train, presets='best_quality')

print(predictor.leaderboard())

predict_proba = predictor.predict_proba(df_test)

y_pred_proba = predict_proba.to_numpy()

"""### write"""

with open('proteinBert_pretrained_300_dim_automl_log_loss.csv', 'w') as csvfile:
    writer = csv.writer(csvfile, delimiter=',')
    lst = list()
    for i in range(18):
        lst.append('class'+str(i))
    lst.insert(0, "name")
    writer.writerow(lst)
    for i, protein in enumerate(proteins_test):
        lst = y_pred_proba[i, :].tolist()
        lst.insert(0, protein)
        writer.writerow(lst)


predictor.refit_full(model='best', set_best_to_refit_full=True)

predict_proba = predictor.predict_proba(df_test)

y_pred_proba = predict_proba.to_numpy()

"""### write"""

with open('proteinBert_pretrained_300_dim_automl_log_loss_refit_full.csv', 'w') as csvfile:
    writer = csv.writer(csvfile, delimiter=',')
    lst = list()
    for i in range(18):
        lst.append('class'+str(i))
    lst.insert(0, "name")
    writer.writerow(lst)
    for i, protein in enumerate(proteins_test):
        lst = y_pred_proba[i, :].tolist()
        lst.insert(0, protein)
        writer.writerow(lst)
